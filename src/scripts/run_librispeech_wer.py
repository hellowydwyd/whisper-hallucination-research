"""
LibriSpeech WER æµ‹è¯•å®éªŒ
========================

æµ‹è¯• Whisper åœ¨æ­£å¸¸è¯­éŸ³ä¸Šçš„è¯é”™è¯¯ç‡ (WER)
éªŒè¯æ¨¡å‹åœ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§

è¿è¡Œæ–¹å¼:
    conda activate d2l
    python run_librispeech_wer.py --quick     # å¿«é€Ÿæµ‹è¯• (100 æ ·æœ¬)
    python run_librispeech_wer.py             # å®Œæ•´æµ‹è¯•
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

import pandas as pd
import numpy as np
from tqdm import tqdm
import json
from datetime import datetime
import re

from config import DATA_DIR, OUTPUT_DIR, SPEECH_DIR
from models.whisper_model import WhisperASR
from utils.metrics import calculate_wer, calculate_cer


def normalize_text(text: str) -> str:
    """
    æ ‡å‡†åŒ–æ–‡æœ¬ç”¨äº WER è®¡ç®—
    - è½¬å°å†™
    - ç§»é™¤æ ‡ç‚¹
    - è§„èŒƒåŒ–ç©ºæ ¼
    """
    text = text.lower()
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    text = re.sub(r'[^\w\s]', '', text)
    # è§„èŒƒåŒ–ç©ºæ ¼
    text = ' '.join(text.split())
    return text


def find_librispeech_data():
    """
    æŸ¥æ‰¾ LibriSpeech æ•°æ®ç›®å½•å’Œè½¬å½•æ–‡ä»¶
    """
    possible_paths = [
        SPEECH_DIR / "librispeech" / "test-clean",
        SPEECH_DIR / "LibriSpeech" / "test-clean",
        DATA_DIR / "LibriSpeech" / "test-clean",
        DATA_DIR / "librispeech" / "test-clean",
    ]
    
    for path in possible_paths:
        if path.exists():
            return path
    
    return None


def load_librispeech_transcripts(data_dir: Path) -> dict:
    """
    åŠ è½½ LibriSpeech è½¬å½•æ–‡æœ¬
    
    LibriSpeech ç›®å½•ç»“æ„:
    test-clean/
        {speaker_id}/
            {chapter_id}/
                {speaker_id}-{chapter_id}-{utterance_id}.flac
                {speaker_id}-{chapter_id}.trans.txt
    """
    transcripts = {}
    
    # éå†æ‰€æœ‰ trans.txt æ–‡ä»¶
    for trans_file in data_dir.rglob("*.trans.txt"):
        with open(trans_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split(' ', 1)
                    if len(parts) == 2:
                        utterance_id, text = parts
                        transcripts[utterance_id] = text
    
    return transcripts


def run_librispeech_wer(
    model_size: str = "large-v3",
    max_samples: int = None,
    quick: bool = False
):
    """
    è¿è¡Œ LibriSpeech WER æµ‹è¯•
    
    Args:
        model_size: Whisper æ¨¡å‹å¤§å°
        max_samples: æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°
        quick: å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    """
    print("\n" + "=" * 60)
    print("   LibriSpeech WER æµ‹è¯•å®éªŒ")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ•°æ®ç›®å½•
    data_dir = find_librispeech_data()
    
    if data_dir is None:
        print("[Error] æ‰¾ä¸åˆ° LibriSpeech æ•°æ®ç›®å½•")
        print("[Error] è¯·å…ˆè¿è¡Œ: python download_datasets.py --dataset librispeech")
        return None
    
    print(f"[LibriSpeech] æ•°æ®ç›®å½•: {data_dir}")
    
    # åŠ è½½è½¬å½•æ–‡æœ¬
    print("[LibriSpeech] åŠ è½½è½¬å½•æ–‡æœ¬...")
    transcripts = load_librispeech_transcripts(data_dir)
    print(f"[LibriSpeech] è½¬å½•æ•°é‡: {len(transcripts)}")
    
    # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
    audio_files = list(data_dir.rglob("*.flac"))
    print(f"[LibriSpeech] éŸ³é¢‘æ–‡ä»¶æ•°: {len(audio_files)}")
    
    if quick:
        max_samples = 100
        print(f"[LibriSpeech] å¿«é€Ÿæ¨¡å¼: é™åˆ¶ {max_samples} æ ·æœ¬")
    
    if max_samples and len(audio_files) > max_samples:
        import random
        random.seed(42)
        audio_files = random.sample(audio_files, max_samples)
    
    # åˆå§‹åŒ–æ¨¡å‹
    print(f"\n[Model] åŠ è½½ Whisper {model_size}...")
    asr = WhisperASR(model_size=model_size, language="en")
    
    # è¿è¡Œæµ‹è¯•
    results = []
    
    print(f"\n[Experiment] å¼€å§‹æµ‹è¯• {len(audio_files)} ä¸ªéŸ³é¢‘...")
    
    for audio_file in tqdm(audio_files, desc="è½¬å½•ä¸­"):
        try:
            # è·å– utterance ID
            utterance_id = audio_file.stem
            
            # è·å–å‚è€ƒæ–‡æœ¬
            reference = transcripts.get(utterance_id, "")
            if not reference:
                continue
            
            # è½¬å½•
            result = asr.transcribe(str(audio_file))
            hypothesis = result['text']
            
            # æ ‡å‡†åŒ–
            ref_norm = normalize_text(reference)
            hyp_norm = normalize_text(hypothesis)
            
            # è®¡ç®— WER
            wer = calculate_wer(ref_norm, hyp_norm)
            cer = calculate_cer(ref_norm, hyp_norm)
            
            record = {
                'file': audio_file.name,
                'utterance_id': utterance_id,
                'reference': reference,
                'hypothesis': hypothesis,
                'ref_normalized': ref_norm,
                'hyp_normalized': hyp_norm,
                'wer': wer,
                'cer': cer,
                'ref_word_count': len(ref_norm.split()),
                'hyp_word_count': len(hyp_norm.split()),
            }
            results.append(record)
            
        except Exception as e:
            print(f"\n[Error] {audio_file.name}: {e}")
    
    # åˆ†æç»“æœ
    df = pd.DataFrame(results)
    
    print("\n" + "=" * 60)
    print("WER æµ‹è¯•ç»“æœ")
    print("=" * 60)
    
    # è®¡ç®—æ€»ä½“ WER (åŠ æƒå¹³å‡)
    total_ref_words = df['ref_word_count'].sum()
    total_errors = (df['wer'] * df['ref_word_count']).sum()
    overall_wer = total_errors / total_ref_words if total_ref_words > 0 else 0
    
    # è®¡ç®—æ€»ä½“ CER
    overall_cer = df['cer'].mean()
    
    print(f"\nğŸ“Š æ€»ä½“æŒ‡æ ‡:")
    print(f"  - æµ‹è¯•æ ·æœ¬æ•°: {len(df)}")
    print(f"  - æ€»è¯æ•°: {total_ref_words}")
    print(f"  - æ€»ä½“ WER: {overall_wer:.2%}")
    print(f"  - å¹³å‡ CER: {overall_cer:.2%}")
    print(f"  - WER æ ‡å‡†å·®: {df['wer'].std():.2%}")
    
    # WER åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ“Š WER åˆ†å¸ƒ:")
    print(f"  - æœ€å° WER: {df['wer'].min():.2%}")
    print(f"  - 25% åˆ†ä½: {df['wer'].quantile(0.25):.2%}")
    print(f"  - ä¸­ä½æ•°:   {df['wer'].quantile(0.50):.2%}")
    print(f"  - 75% åˆ†ä½: {df['wer'].quantile(0.75):.2%}")
    print(f"  - æœ€å¤§ WER: {df['wer'].max():.2%}")
    
    # å®Œç¾è¯†åˆ«æ¯”ä¾‹
    perfect = (df['wer'] == 0).sum()
    print(f"\nğŸ“Š è¯†åˆ«è´¨é‡:")
    print(f"  - å®Œç¾è¯†åˆ« (WER=0): {perfect} ({perfect/len(df):.1%})")
    print(f"  - WER < 5%: {(df['wer'] < 0.05).sum()} ({(df['wer'] < 0.05).mean():.1%})")
    print(f"  - WER < 10%: {(df['wer'] < 0.10).sum()} ({(df['wer'] < 0.10).mean():.1%})")
    print(f"  - WER > 50%: {(df['wer'] > 0.50).sum()} ({(df['wer'] > 0.50).mean():.1%})")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print(f"\nğŸ“Š è¯†åˆ«ç¤ºä¾‹ (å‰ 5 ä¸ª):")
    for i, row in df.head(5).iterrows():
        print(f"\n  [{i+1}] WER: {row['wer']:.1%}")
        print(f"      å‚è€ƒ: {row['reference'][:60]}...")
        print(f"      è¯†åˆ«: {row['hypothesis'][:60]}...")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    csv_path = OUTPUT_DIR / f"librispeech_wer_{timestamp}.csv"
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\n[Save] CSV: {csv_path}")
    
    summary = {
        'model': model_size,
        'dataset': 'LibriSpeech test-clean',
        'total_samples': len(df),
        'total_words': int(total_ref_words),
        'overall_wer': float(overall_wer),
        'overall_cer': float(overall_cer),
        'wer_std': float(df['wer'].std()),
        'wer_median': float(df['wer'].median()),
        'perfect_rate': float(perfect / len(df)),
    }
    
    json_path = OUTPUT_DIR / f"librispeech_wer_{timestamp}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    print(f"[Save] JSON: {json_path}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    generate_wer_visualization(df, OUTPUT_DIR, timestamp)
    
    return df, summary


def generate_wer_visualization(df: pd.DataFrame, output_dir: Path, timestamp: str):
    """
    ç”Ÿæˆ WER å¯è§†åŒ–
    """
    import matplotlib.pyplot as plt
    
    print("\n[å¯è§†åŒ–] ç”Ÿæˆå›¾è¡¨...")
    
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # å›¾1: WER åˆ†å¸ƒç›´æ–¹å›¾
    ax1 = axes[0, 0]
    ax1.hist(df['wer'], bins=50, color='#3498db', edgecolor='white', alpha=0.8)
    ax1.axvline(df['wer'].mean(), color='red', linestyle='--', linewidth=2, label=f"Mean: {df['wer'].mean():.2%}")
    ax1.axvline(df['wer'].median(), color='green', linestyle='--', linewidth=2, label=f"Median: {df['wer'].median():.2%}")
    ax1.set_xlabel('Word Error Rate (WER)')
    ax1.set_ylabel('Frequency')
    ax1.set_title('Distribution of WER', fontsize=12, fontweight='bold')
    ax1.legend()
    
    # å›¾2: WER ç´¯ç§¯åˆ†å¸ƒ
    ax2 = axes[0, 1]
    sorted_wer = np.sort(df['wer'])
    cumulative = np.arange(1, len(sorted_wer) + 1) / len(sorted_wer)
    ax2.plot(sorted_wer, cumulative, color='#9b59b6', linewidth=2)
    ax2.axhline(0.9, color='gray', linestyle='--', alpha=0.5)
    ax2.axvline(sorted_wer[int(0.9 * len(sorted_wer))], color='gray', linestyle='--', alpha=0.5)
    ax2.set_xlabel('Word Error Rate (WER)')
    ax2.set_ylabel('Cumulative Proportion')
    ax2.set_title('Cumulative Distribution of WER', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # å›¾3: WER vs å¥å­é•¿åº¦
    ax3 = axes[1, 0]
    ax3.scatter(df['ref_word_count'], df['wer'], alpha=0.5, color='#e74c3c', s=20)
    ax3.set_xlabel('Reference Word Count')
    ax3.set_ylabel('WER')
    ax3.set_title('WER vs Sentence Length', fontsize=12, fontweight='bold')
    ax3.set_ylim(0, min(df['wer'].max() * 1.1, 2.0))
    
    # å›¾4: WER åŒºé—´ç»Ÿè®¡
    ax4 = axes[1, 1]
    bins = [0, 0.05, 0.10, 0.20, 0.50, 1.0, float('inf')]
    labels = ['0-5%', '5-10%', '10-20%', '20-50%', '50-100%', '>100%']
    df['wer_bin'] = pd.cut(df['wer'], bins=bins, labels=labels)
    bin_counts = df['wer_bin'].value_counts().reindex(labels)
    colors = ['#2ecc71', '#27ae60', '#f39c12', '#e67e22', '#e74c3c', '#c0392b']
    ax4.bar(labels, bin_counts.values, color=colors, edgecolor='white')
    ax4.set_xlabel('WER Range')
    ax4.set_ylabel('Count')
    ax4.set_title('WER Distribution by Range', fontsize=12, fontweight='bold')
    for i, v in enumerate(bin_counts.values):
        ax4.text(i, v + 1, f'{v}', ha='center', fontsize=9)
    
    plt.tight_layout()
    
    fig_path = output_dir / f"librispeech_wer_{timestamp}.png"
    plt.savefig(fig_path, dpi=150, bbox_inches='tight')
    print(f"[å¯è§†åŒ–] å›¾è¡¨å·²ä¿å­˜: {fig_path}")
    
    plt.close()


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='LibriSpeech WER æµ‹è¯•')
    parser.add_argument('--model', type=str, default='large-v3', help='Whisper æ¨¡å‹å¤§å°')
    parser.add_argument('--max-samples', type=int, default=None, help='æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ (100 æ ·æœ¬)')
    
    args = parser.parse_args()
    
    df, summary = run_librispeech_wer(
        model_size=args.model,
        max_samples=args.max_samples,
        quick=args.quick
    )
    
    if summary:
        print("\n" + "=" * 60)
        print("ğŸ‰ LibriSpeech WER æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        print(f"  æ¨¡å‹: {summary['model']}")
        print(f"  æ ·æœ¬æ•°: {summary['total_samples']}")
        print(f"  æ€»ä½“ WER: {summary['overall_wer']:.2%}")


if __name__ == "__main__":
    main()
